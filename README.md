# Tool-for-creating-lip-recognition-datasets
The following python code is the first step to creating an open source tool which will be used to create datasets that could be used to train lip recognition machine learning algorithms. The program typical takes a given video URL (typically from youtube) and downloads the video along with the available English subtitles. It then chops the video into segments per word or per sentence depending on the what settings are specified. Once the videos are chopped per sentence or per-word the audio is extracted and stored into a separate chunks and the files are copied without the audio and stored separately. Afterwards face recognition is applied onto the video files that do not contain the audio. The 68 landmark points position are extracted for every frame, face recognition is applied on every frame and the result is True if a face is found False is a face isn't found. If a face is found the region of the lips is cropped. All of the results are saved locally. No subtitle to audio or audio to video alignment is applied at the moment. The video is chopped at the times in which subtitles are presented in the video. Simply open and run main.py by changing the URL and filename value. Also a DEMO_face_detect.py presents how face recognition is applied in real time from the local camera. I appologies in advance there are alot of improvements that need to be made. I am not a software engineer nor I hold a computer science degree at the moment but I am get there.
